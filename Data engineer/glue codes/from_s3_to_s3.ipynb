{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": false,
				"deletable": false,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": false,
				"deletable": false,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": false,
				"deletable": false,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 3.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.37.0 \nCurrent idle_timeout is 2880 minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 3.0\nPrevious worker type: G.1X\nSetting new worker type to: G.1X\nPrevious number of workers: 5\nSetting new number of workers to: 5\nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::393747608406:role/glue_role_redsfhit_project\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: 1ff8a66b-15d9-43b9-8b6e-361005fdd474\nJob Type: glueetl\nApplying the following default arguments:\n--glue_kernel_version 0.37.0\n--enable-glue-datacatalog true\nWaiting for session 1ff8a66b-15d9-43b9-8b6e-361005fdd474 to get into ready status...\nSession 1ff8a66b-15d9-43b9-8b6e-361005fdd474 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Create a DynamicFrame from a table in the AWS Glue Data Catalog and display its schema\n",
			"metadata": {
				"editable": false,
				"deletable": false,
				"tags": [],
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "dyf = glueContext.create_dynamic_frame.from_catalog(database='redsfhift_data', table_name='btc')\ndyf.printSchema()",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- timestamp: long\n|-- open: string\n|-- high: string\n|-- low: string\n|-- close: string\n|-- volume_(btc): string\n|-- volume_(currency): string\n|-- weighted_price: string\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "btc_dyf = ApplyMapping.apply(\n    frame = dyf, \n    mappings = [\n        (\"timestamp\",\"long\",\"timestamp\",\"Integer\"), \n        (\"open\",\"string\",\"open\",\"double\"), \n        (\"high\",\"string\",\"high\",\"double\"), \n        (\"low\",\"string\",\"low\",\"double\"), \n        (\"close\",\"string\",\"close\",\"double\"),\n        (\"volume_(btc)\",\"string\",\"volume_(btc)\",\"double\"), \n        (\"volume_(currency)\",\"string\",\"volume_(currency)\",\"double\"), \n        (\"weighted_price\",\"string\",\"weighted_price\",\"double\")\n    ],\n    transformation_ctx = \"btc_dyf_ctx\"\n)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Convert the DynamicFrame to a Spark DataFrame and display a sample of the data\n",
			"metadata": {
				"editable": false,
				"deletable": false,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "from datetime import datetime\nfrom pyspark.sql.functions import col, udf\nfrom pyspark.sql.types import StringType,IntegerType,TimestampType\ndate_UDF=udf(lambda x:datetime.fromtimestamp(x),TimestampType()) \nyear_UDF = udf(lambda x:x.year,IntegerType()) \nmonth_UDF=  udf(lambda x:x.month,IntegerType())   ",
			"metadata": {
				"trusted": true
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df = btc_dyf.toDF()\ndf=df.withColumn(\"date\",date_UDF(col(\"Timestamp\")))\ndf=df.withColumn(\"Year\",year_UDF(col(\"date\")))\ndf=df.withColumn(\"Month\",month_UDF(col(\"date\")))\ndf = df.replace(float('nan'), None)\ndf.createOrReplaceTempView(\"table_df\")\n#df.printSchema()\ndf.show()",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----------+----+----+----+-----+------------+-----------------+--------------+-------------------+----+-----+\n| timestamp|open|high| low|close|volume_(btc)|volume_(currency)|weighted_price|               date|Year|Month|\n+----------+----+----+----+-----+------------+-----------------+--------------+-------------------+----+-----+\n|1325317920|4.39|4.39|4.39| 4.39|  0.45558087|     2.0000000193|          4.39|2011-12-31 07:52:00|2011|   12|\n|1325317980|null|null|null| null|        null|             null|          null|2011-12-31 07:53:00|2011|   12|\n|1325318040|null|null|null| null|        null|             null|          null|2011-12-31 07:54:00|2011|   12|\n|1325318100|null|null|null| null|        null|             null|          null|2011-12-31 07:55:00|2011|   12|\n|1325318160|null|null|null| null|        null|             null|          null|2011-12-31 07:56:00|2011|   12|\n|1325318220|null|null|null| null|        null|             null|          null|2011-12-31 07:57:00|2011|   12|\n|1325318280|null|null|null| null|        null|             null|          null|2011-12-31 07:58:00|2011|   12|\n|1325318340|null|null|null| null|        null|             null|          null|2011-12-31 07:59:00|2011|   12|\n|1325318400|null|null|null| null|        null|             null|          null|2011-12-31 08:00:00|2011|   12|\n|1325318460|null|null|null| null|        null|             null|          null|2011-12-31 08:01:00|2011|   12|\n|1325318520|null|null|null| null|        null|             null|          null|2011-12-31 08:02:00|2011|   12|\n|1325318580|null|null|null| null|        null|             null|          null|2011-12-31 08:03:00|2011|   12|\n|1325318640|null|null|null| null|        null|             null|          null|2011-12-31 08:04:00|2011|   12|\n|1325318700|null|null|null| null|        null|             null|          null|2011-12-31 08:05:00|2011|   12|\n|1325318760|null|null|null| null|        null|             null|          null|2011-12-31 08:06:00|2011|   12|\n|1325318820|null|null|null| null|        null|             null|          null|2011-12-31 08:07:00|2011|   12|\n|1325318880|null|null|null| null|        null|             null|          null|2011-12-31 08:08:00|2011|   12|\n|1325318940|null|null|null| null|        null|             null|          null|2011-12-31 08:09:00|2011|   12|\n|1325319000|null|null|null| null|        null|             null|          null|2011-12-31 08:10:00|2011|   12|\n|1325319060|null|null|null| null|        null|             null|          null|2011-12-31 08:11:00|2011|   12|\n+----------+----+----+----+-----+------------+-----------------+--------------+-------------------+----+-----+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Write the data in the DynamicFrame to a location in Amazon S3 and a table for it in the AWS Glue Data Catalog\n",
			"metadata": {
				"editable": false,
				"deletable": false,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "r1=spark.sql(\"select  avg(Close), Year   from table_df where Close IS NOT NULL  group by 2 order by 2  ;\")",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "r1.write.mode(\"overwrite\").partitionBy(\"Year\").csv(\"s3://redshift-tutorial-datasets/Glue_data/btc/btc_agg.csv\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from awsglue.dynamicframe import DynamicFrame\nr2=spark.sql(\"select  sum(weighted_price), Year   from table_df where Close IS NOT NULL  group by 2 order by 2  ;\")\ndyf2=DynamicFrame.fromDF(r2, glueContext, \"weighted_price\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "glueContext.write_dynamic_frame.from_options(frame = dyf2, connection_type = \"s3\", format = \"csv\", connection_options = {\"path\": \"s3://redshift-tutorial-datasets/Glue_data/btc/year_agg.csv \",\"partitionKeys\": ['Year']}, transformation_ctx = \"year_agg_trf\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "<awsglue.dynamicframe.DynamicFrame object at 0x7f17194981d0>\n",
					"output_type": "stream"
				}
			]
		}
	]
}